{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f8083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import pathlib\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60871b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_ops.tf = tf.compat.v1\n",
    "tf.gfile = tf.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb8a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "  model_file = model_name + '.tar.gz'\n",
    "  model_dir = tf.keras.utils.get_file(\n",
    "    fname=model_name, \n",
    "    origin=base_url + model_file,\n",
    "    untar=True)\n",
    "\n",
    "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "\n",
    "  model = tf.saved_model.load(str(model_dir))\n",
    "  model = model.signatures['serving_default']\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00644f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = 'object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f6a9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('object_detection/test_images/image1.jpg'),\n",
       " WindowsPath('object_detection/test_images/image2.jpg'),\n",
       " WindowsPath('object_detection/test_images/image3.jpg'),\n",
       " WindowsPath('object_detection/test_images/IMG_1129.JPG')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('object_detection/test_images')\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "TEST_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8cb73f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "detection_model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e23fff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "  image = np.asarray(image)\n",
    "  input_tensor = tf.convert_to_tensor(image)\n",
    "  input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "  output_dict = model(input_tensor)\n",
    "\n",
    "  num_detections = int(output_dict.pop('num_detections'))\n",
    "  output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "  output_dict['num_detections'] = num_detections\n",
    "\n",
    "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "   \n",
    "  if 'detection_masks' in output_dict:\n",
    "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "               image.shape[0], image.shape[1])      \n",
    "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                       tf.uint8)\n",
    "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "    \n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a1224a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_inference(model, image_path):\n",
    "    image_np = image_path\n",
    "    image_np=cv2.cvtColor(image_np,cv2.COLOR_BGR2RGB)\n",
    "    output_dict = run_inference_for_single_image(model, image_np)\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=2)\n",
    "    image_np=cv2.cvtColor(image_np,cv2.COLOR_BGR2RGB)\n",
    "    bicycle_detect(image_np,output_dict['detection_classes'],output_dict['detection_scores'],output_dict['detection_boxes'])\n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceded823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def bicycle_detect(image,classes,score,boxes):\n",
    "    \n",
    "    global vahicalName\n",
    "    \n",
    "    for i in range (10):\n",
    "        if(classes[i]==3  and score[i]>0.6):\n",
    "            vahicalName=\"CAR\"\n",
    "            print(\"car\")\n",
    "        elif(classes[i]==4  and score[i]>0.6):\n",
    "            vahicalName=\"motorbike\"\n",
    "            print(\"motorbike\")\n",
    "        elif(classes[i]==6  and score[i]>0.6):\n",
    "            vahicalName=\"BUS\"\n",
    "            print(\"bus\")\n",
    "        else:\n",
    "            vahicalName=\"No Vehicles\"\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef4b1556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bus\n",
      "bus\n",
      "bus\n",
      "bus\n",
      "motorbike\n",
      "motorbike\n",
      "motorbike\n",
      "motorbike\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gihan\\anaconda3\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\gihan\\anaconda3\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-10-3160d2fd8fa6>\", line 191, in cl\n",
      "  File \"C:\\Users\\gihan\\anaconda3\\lib\\tkinter\\__init__.py\", line 1320, in update_idletasks\n",
      "    self.tk.call('update', 'idletasks')\n",
      "_tkinter.TclError: can't invoke \"update\" command: application has been destroyed\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter\n",
    "from threading import Thread, Event\n",
    "\n",
    "import pyfirmata\n",
    "import time\n",
    "from pyfirmata import Arduino,util,STRING_DATA\n",
    "import pyttsx3\n",
    "\n",
    "textSpeech= pyttsx3.init()\n",
    "vahicalName=\"No Vehicles\"\n",
    "\n",
    "x=100\n",
    "distance=0\n",
    "xx=0\n",
    "event = Event()\n",
    "source=cv2.VideoCapture(r'F:\\research full codes\\Samples\\Comp 6.mp4')\n",
    "#source=cv2.VideoCapture(0)\n",
    "width=480\n",
    "fcx=width//2\n",
    "\n",
    "\n",
    "audioStatus=False\n",
    "\n",
    "\n",
    "kernel=np.array([[-1,0,1],\n",
    "                 [-2,0,2],\n",
    "                 [-1,0,1]],np.float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "port='COM6'                     #Arduino ports\n",
    "\n",
    "board = pyfirmata.Arduino('COM6')\n",
    "led1 = board.get_pin('d:11:o')\n",
    "led2 = board.get_pin('d:12:o')\n",
    "led3 = board.get_pin('d:13:o')\n",
    "\n",
    "stop_threads=False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def modify_variable(var):\n",
    "    global distance\n",
    "    global vahicalName\n",
    "    cop=distance\n",
    "    while True:\n",
    "        \n",
    "        ret,imgs=source.read()\n",
    "        img=cv2.resize(imgs,(480,340))\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        blur=cv2.blur(gray,(5,5))\n",
    "\n",
    "        conv=cv2.filter2D(blur,-1,kernel)\n",
    "\n",
    "\n",
    "        img[:,fcx]=(0,255,0)\n",
    "\n",
    "\n",
    "        for i in range(240):\n",
    "            for j in range(240-(i),0,-1):\n",
    "                conv[i,j]=0\n",
    "                gray[i,j]=0\n",
    "                #print(\"*\", end=\"\")\n",
    "       # print()\n",
    "    \n",
    "        ret, thresh = cv2.threshold(conv, 50, 255, 0)\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for cnt in contours:\n",
    "            area=cv2.contourArea(cnt)\n",
    "            #print(area)\n",
    "            if(area>300 and area>310):\n",
    "                cv2.drawContours(img, [cnt], -1, (0,0,255), 3)            \n",
    "                rect = cv2.minAreaRect(cnt)\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.int0(box)\n",
    "                cv2.drawContours(img,[box],0,(0,255,0),2)\n",
    "\n",
    "\n",
    "                M=cv2.moments(cnt)\n",
    "                cx = int(M['m10']/M['m00'])\n",
    "                cy = int(M['m01']/M['m00'])\n",
    "                cv2.circle(img,(cx,cy),5,(0,255,255),-1)\n",
    "\n",
    "                if(cx<fcx and cy>150):\n",
    "                    cv2.line(img,(cx,cy),(fcx,cy),(255,0,0,),2)\n",
    "                    cop=fcx-cx\n",
    "                    cv2.putText(img,\"distance: \"+str(cop),(fcx,170),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2)\n",
    "                    xx=cop\n",
    "\n",
    "                #if(distance<=150):\n",
    "                        #print (\"Distance is : \"+str(distance))\n",
    "\n",
    "        img=show_inference(detection_model,img)\n",
    "        #print(detection_model)\n",
    "        cv2.imshow('LIVE',img)\n",
    "\n",
    "        if(distance<=100): #blinking LED\n",
    "            led1.write(1)\n",
    "            led2.write(0)\n",
    "        else:\n",
    "            led1.write(0)\n",
    "            led2.write(1)\n",
    "        \n",
    "        board.send_sysex(STRING_DATA,util.str_to_two_byte_iter(\"Distance is \"+str(distance)))\n",
    "        board.send_sysex(STRING_DATA,util.str_to_two_byte_iter(vahicalName))\n",
    "        \n",
    "        #print(cop)\n",
    "        distance=cop\n",
    "        #cv2.imshow('thresh',thresh)\n",
    "        #cv2.imshow('gray',gray)\n",
    "        key=cv2.waitKey(100)\n",
    "\n",
    "        if(key==27):\n",
    "            global audioStatus\n",
    "            audioStatus = False\n",
    "            break\n",
    "        \n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "    source.release()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "t = Thread(target=modify_variable, args=(distance, ))\n",
    "t.start()\n",
    "\n",
    "\n",
    "window=tkinter.Tk()\n",
    "\n",
    "def audioCl(): \n",
    "    global audioStatus\n",
    "    audioStatus = True\n",
    "    t2 = Thread(target=audio, args=(distance, ))\n",
    "    t2.start()\n",
    "\n",
    "\n",
    "def audioStop(): \n",
    "    global audioStatus\n",
    "    audioStatus = False\n",
    "\n",
    "def audio(dis):               ############ Audio Reading\n",
    "    \n",
    "    global audioStatus\n",
    "    global vahicalName\n",
    "    while(audioStatus):\n",
    "        global distance\n",
    "        text='distance is ' + str(distance) + 'and behind ' + vahicalName\n",
    "        textSpeech.say(text)\n",
    "        textSpeech.runAndWait()\n",
    "        \n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def callcl():\n",
    "    t1 = Thread(target=cl, args=(distance, ))\n",
    "    t1.start()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cl(some):\n",
    "    global distance\n",
    "    num=0\n",
    "    \n",
    "    \n",
    "    while(True):\n",
    "        #num=num+1\n",
    "        #print(\"heloooo\")\n",
    "        distanceNew=tkinter.Label(window,text=str(distance),padx='10',font=(\"Arial Bold\",25),background=\"#004E60\",foreground=\"white\")\n",
    "        distanceNew.place(x=420,y=140)\n",
    "        if (distance<=100):\n",
    "            #print('sss')\n",
    "            emergency1=tkinter.Label(window,text=\"RISK \",padx='10',font=(\"Arial Bold\",25),background=\"#F90808\",foreground=\"white\")\n",
    "            emergency1.place(x=900,y=200)\n",
    "            window.update_idletasks()\n",
    "        else:\n",
    "            emergency1=tkinter.Label(window,text=\"SAFE\",padx='10',font=(\"Arial Bold\",25),background=\"#19FC06\",foreground=\"white\")\n",
    "            emergency1.place(x=900,y=200)\n",
    "            window.update_idletasks()\n",
    "            \n",
    "        \n",
    "        \n",
    "        window.update_idletasks()\n",
    "\n",
    "\n",
    "\n",
    "window=tkinter.Tk()\n",
    "window.title(\"Mission\")\n",
    "window.geometry('1500x650')\n",
    "window.configure(bg='#004E60')\n",
    "title=tkinter.Label(window,text=\"MotorBick Assistent Tool\",padx='250',font=(\"Arial Bold\",50),background=\"#004E60\",foreground=\"white\")\n",
    "title.pack()\n",
    "midLine=tkinter.Label(window,text=\"Disane to Middle Line :\",padx='10',font=(\"Arial Bold\",25),background=\"#004E60\",foreground=\"white\")\n",
    "distanceNew=tkinter.Label(window,text=\"0\",padx='10',font=(\"Arial Bold\",25),background=\"#004E60\",foreground=\"white\")\n",
    "\n",
    "behindVehicals=tkinter.Label(window,text=\"Behind Vehicals :\",padx='10',font=(\"Arial Bold\",25),background=\"#004E60\",foreground=\"white\")\n",
    "lineDetect=tkinter.Label(window,text=\"one line\",padx='10',font=(\"Arial Bold\",25),background=\"#FFFF00\",foreground=\"black\")\n",
    "vehicalsNew=tkinter.Label(window,text=\"0\",padx='10',font=(\"Arial Bold\",25),background=\"#004E60\",foreground=\"white\")\n",
    "\n",
    "emergency1=tkinter.Label(window,text=\"SAFE\",padx='10',font=(\"Arial Bold\",25),background=\"#19FC06\",foreground=\"white\")\n",
    "emergency2=tkinter.Label(window,text=\"RISK\",padx='10',font=(\"Arial Bold\",25),background=\"#F90808\",foreground=\"white\")\n",
    "\n",
    "\n",
    "\n",
    "#buttons\n",
    "\n",
    "startBtn= tkinter.Button(window,text='Enter',font=(\"Arial Bold\",25),bg=\"#100BF7\",fg=\"white\",borderwidth = '4',activebackground=\"red\"\n",
    "                        ,bd='7',relief='raised',command=callcl)\n",
    "\n",
    "audioStrtBtn= tkinter.Button(window,text='Start Audio',font=(\"Arial Bold\",25),bg=\"#100BF7\",fg=\"white\",borderwidth = '4',activebackground=\"red\"\n",
    "                        ,bd='7',relief='raised',command=audioCl)\n",
    "\n",
    "audioStopBtn= tkinter.Button(window,text='Stop Audio',font=(\"Arial Bold\",25),bg=\"#100BF7\",fg=\"white\",borderwidth = '4',activebackground=\"red\"\n",
    "                        ,bd='7',relief='raised',command=audioStop)\n",
    "\n",
    "\n",
    "\n",
    "midLine.place(x=10,y=140)\n",
    "startBtn.place(x=1200,y=20)\n",
    "audioStrtBtn.place(x=1200,y=100)\n",
    "audioStopBtn.place(x=1200,y=180)\n",
    "emergency1.place(x=900,y=200)\n",
    "lineDetect.place(x=1200,y=200)\n",
    "behindVehicals.place(x=10,y=400)\n",
    "emergency2.place(x=900,y=400)\n",
    "distanceNew.place(x=420,y=140)\n",
    "vehicalsNew.place(x=420,y=400)\n",
    "\n",
    "window.mainloop()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1986bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
