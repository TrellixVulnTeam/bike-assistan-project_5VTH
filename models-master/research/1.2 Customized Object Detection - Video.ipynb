{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import pathlib\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_ops.tf = tf.compat.v1\n",
    "tf.gfile = tf.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "  model_file = model_name + '.tar.gz'\n",
    "  model_dir = tf.keras.utils.get_file(\n",
    "    fname=model_name, \n",
    "    origin=base_url + model_file,\n",
    "    untar=True)\n",
    "\n",
    "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "\n",
    "  model = tf.saved_model.load(str(model_dir))\n",
    "  model = model.signatures['serving_default']\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = 'object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('object_detection/test_images')\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "TEST_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "detection_model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "  image = np.asarray(image)\n",
    "  input_tensor = tf.convert_to_tensor(image)\n",
    "  input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "  output_dict = model(input_tensor)\n",
    "\n",
    "  num_detections = int(output_dict.pop('num_detections'))\n",
    "  output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "  output_dict['num_detections'] = num_detections\n",
    "\n",
    "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "   \n",
    "  if 'detection_masks' in output_dict:\n",
    "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "               image.shape[0], image.shape[1])      \n",
    "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                       tf.uint8)\n",
    "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "    \n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_inference(model, image_path):\n",
    "    image_np = image_path\n",
    "    image_np=cv2.cvtColor(image_np,cv2.COLOR_BGR2RGB)\n",
    "    output_dict = run_inference_for_single_image(model, image_np)\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=2)\n",
    "    image_np=cv2.cvtColor(image_np,cv2.COLOR_BGR2RGB)\n",
    "    bicycle_detect(image_np,output_dict['detection_classes'],output_dict['detection_scores'],output_dict['detection_boxes'])\n",
    "    #return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def bicycle_detect(image,classes,score,boxes):\n",
    "    \n",
    "    for i in range(10):\n",
    "        if(classes[i]==2 and score[i]>0.8):\n",
    "            \n",
    "            h,w=image.shape[0:2]\n",
    "            \n",
    "            ymin,xmin,ymax,xmax=boxes[i]\n",
    "\n",
    "            now = datetime.now()\n",
    "            dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "            \n",
    "            center=(int(((xmin+xmax)/2)*w),int(((ymin+ymax)/2)*h))\n",
    "            cv2.circle(image,center,10,(0,0,255),-1)\n",
    "            \n",
    "            file_name=os.path.join('E:/TEST/',dt_string+'.jpg')\n",
    "            cv2.imwrite(file_name,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter\n",
    "\n",
    "#line detection codes strt\n",
    "\n",
    "x=100\n",
    "video=cv2.VideoCapture(r'F:\\research full codes\\Samples\\Comp 7.mp4')\n",
    "\n",
    "\n",
    "\n",
    "width=480\n",
    "fcx=width//2\n",
    "\n",
    "\n",
    "kernel=np.array([[-1,0,1],\n",
    "                 [-2,0,2],\n",
    "                 [-1,0,1]],np.float)\n",
    "\n",
    "\n",
    "\n",
    "while(True):\n",
    "    ret,imgs=video.read()\n",
    "    img=cv2.resize(imgs,(480,340))\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    blur=cv2.blur(gray,(5,5))\n",
    "    \n",
    "    conv=cv2.filter2D(blur,-1,kernel)\n",
    "    \n",
    "    img[:,fcx]=(0,255,0)\n",
    "    \n",
    "    \n",
    "    for i in range(240):\n",
    "        for j in range(240-(i),0,-1):\n",
    "            conv[i,j]=0\n",
    "            gray[i,j]=0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ret, thresh = cv2.threshold(conv, 50, 255, 0)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for cnt in contours:\n",
    "        area=cv2.contourArea(cnt)\n",
    "        #print(area)\n",
    "        if(area>300 and area>310):\n",
    "            cv2.drawContours(img, [cnt], -1, (0,0,255), 3)            \n",
    "            rect = cv2.minAreaRect(cnt)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            cv2.drawContours(img,[box],0,(0,255,0),2)\n",
    "            \n",
    "            \n",
    "            M=cv2.moments(cnt)\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            cv2.circle(img,(cx,cy),5,(0,255,255),-1)\n",
    "            \n",
    "            if(cx<fcx and cy>150):\n",
    "                cv2.line(img,(cx,cy),(fcx,cy),(255,0,0,),2)\n",
    "                distance=fcx-cx\n",
    "                cv2.putText(img,\"distance: \"+str(distance),(fcx,170),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2)\n",
    "                \n",
    "            #if(distance<=150):\n",
    "                    #print (\"Distance is : \"+str(distance))\n",
    "            \n",
    "    \n",
    "    img=show_inference(detection_model,img)\n",
    "    cv2.imshow('LIVE',img)\n",
    "    #cv2.imshow('thresh',thresh)\n",
    "    #cv2.imshow('gray',gray)\n",
    "    key=cv2.waitKey(1)\n",
    "\n",
    "    if(key==27):\n",
    "        break\n",
    "    \n",
    "    \n",
    "   # img=show_inference(detection_model,img)\n",
    "   # cv2.imshow('LIVE',img)\n",
    "   # k=cv2.waitKey(1)\n",
    "    \n",
    "    #if(k==27):\n",
    "    #    break\n",
    "#cv2.destroyAllWindows()\n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
